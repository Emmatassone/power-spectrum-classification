{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ffa3e83-4924-444c-825d-c170f06c3db5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, Dropout\n",
    "from tensorflow.keras.callbacks import Callback\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6051f36f-e18d-4f99-afc1-b10ce60b70fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class PlotValidationLoss(Callback):\n",
    "    def __init__(self,bin_factor):\n",
    "        self.bin_factor=bin_factor\n",
    "        self.val_losses = []\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "    \n",
    "        val_loss = logs.get('val_loss')\n",
    "        print(f\"Epoch {epoch+1}, Validation Loss: {val_loss:.4f}\")\n",
    "        self.val_losses.append(val_loss)\n",
    "        if (epoch+1) % 15 == 0 or epoch == 0:\n",
    "            self.plot_validation_loss()\n",
    "\n",
    "    def plot_validation_loss(self):\n",
    "        epochs_range = range(0, len(self.val_losses))\n",
    "        plt.plot(epochs_range, self.val_losses, 'b', label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.title('Validation Loss')\n",
    "        plt.legend()\n",
    "        plt.savefig('Training-CNN_Validation_Error_'+str(self.bin_factor)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cf9df0f-2fa5-4223-8a32-5db7a0d9559e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "import os\n",
    "from preprocessing import Preprocessing\n",
    "path_BH = os.path.join('data', 'BH')\n",
    "path_NS = os.path.join('data', 'NS')\n",
    "preprocessor = Preprocessing() \n",
    "\n",
    "bin_factor=10\n",
    "\n",
    "BH_powerspectra = preprocessor.collect_all_powerspectra(path_BH, bin_factor=bin_factor, BH=True)\n",
    "NS_powerspectra = preprocessor.collect_all_powerspectra(path_NS, bin_factor=bin_factor, BH=False)\n",
    "\n",
    "powerspectra=np.append(np.array(BH_powerspectra),np.array(NS_powerspectra),axis=0)\n",
    "#data=pd.DataFrame(powerspectra,columns=['freq','power','error','BH?'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6eccf34-86da-4758-a557-2395f6616bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(131072, 2)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "powerspectra[:,:,0:2].reshape(-1,2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "8a89f6d0-f744-44c4-a9df-c257ebb0e3e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# post_processing_time = time.time()\n",
    "X = powerspectra[:,:,0:2].reshape(-1,2)\n",
    "y = powerspectra[:,:,3].flatten()\n",
    "\n",
    "# Assuming 'X' is your input data\n",
    "# Calculate mean and standard deviation\n",
    "mean = np.mean(X, axis=0)\n",
    "std_dev = np.std(X, axis=0)\n",
    "X_standardized = (X - mean) / std_dev\n",
    "\n",
    "#mean = np.mean(y, axis=0)\n",
    "#std_dev = np.std(y, axis=0)\n",
    "#y_standardized = (y - mean) / std_dev\n",
    "# Standardize the data\n",
    "\n",
    "# Split data into training, validation, and testing sets\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_standardized, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f3d83124-b842-454e-b907-2ce1f403273a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#X_train, X_val, X_test=[data.reshape([8,-1,1]) for data in [X_train,X_val, X_test]]\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes = 2)\n",
    "y_val = keras.utils.to_categorical(y_val, num_classes = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "473b04e2-1f3c-45e4-9208-1763482ae2e8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19661, 2)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9b2fda6e-f2c2-4220-be5e-d70774c71a55",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[ 4.86232521],\n",
       "        [ 2.95907641],\n",
       "        [-0.28471217],\n",
       "        ...,\n",
       "        [-0.28471217],\n",
       "        [-0.32702184],\n",
       "        [-0.28471217]],\n",
       "\n",
       "       [[-0.32702184],\n",
       "        [-0.28471217],\n",
       "        [-0.32702184],\n",
       "        ...,\n",
       "        [-0.32702184],\n",
       "        [-0.28471217],\n",
       "        [-0.32702184]]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Flatten the input data\n",
    "#X_train.reshape((-1,30,1))\n",
    "X_val.flatten().reshape((-1,int(39322/2),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "c133eb8a-8d6d-406b-b055-ab5f559e774a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-0.28471217],\n",
       "        [-0.32702184],\n",
       "        [-0.28471217],\n",
       "        ...,\n",
       "        [-0.28471217],\n",
       "        [-0.32702184],\n",
       "        [-0.28471217]],\n",
       "\n",
       "       [[-0.32702184],\n",
       "        [-0.28471217],\n",
       "        [-0.32702184],\n",
       "        ...,\n",
       "        [-0.32702184],\n",
       "        [-0.28471217],\n",
       "        [-0.32702184]],\n",
       "\n",
       "       [[-0.28471217],\n",
       "        [-0.32702184],\n",
       "        [-0.28471217],\n",
       "        ...,\n",
       "        [-0.28471217],\n",
       "        [-0.32702184],\n",
       "        [ 4.13387655]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-0.32702184],\n",
       "        [-0.28471217],\n",
       "        [-0.32702184],\n",
       "        ...,\n",
       "        [ 2.93300743],\n",
       "        [-0.28471217],\n",
       "        [-0.32702184]],\n",
       "\n",
       "       [[ 5.19786361],\n",
       "        [ 2.89119314],\n",
       "        [-0.28471217],\n",
       "        ...,\n",
       "        [-0.28471217],\n",
       "        [-0.32702184],\n",
       "        [-0.28471217]],\n",
       "\n",
       "       [[-0.32702184],\n",
       "        [-0.28471217],\n",
       "        [-0.32702184],\n",
       "        ...,\n",
       "        [-0.32702184],\n",
       "        [-0.28471217],\n",
       "        [-0.32702184]]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.reshape((-1,int(len(X_train)/10),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "02ddd295-4373-4e54-b9a8-153b70f4e8d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((91750, 2, 1), (91750, 2), (19661, 2, 1), (19661, 2))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape,X_val.shape,y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d40339b5-2b0c-49d8-84d9-e6a2e654ec11",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv1d_2. Consider increasing the input size. Received input shape [None, 2, 1] which would produce output shape with a zero or negative value in a dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m model \u001b[38;5;241m=\u001b[39m Sequential()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Add 1D convolutional layer\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m model\u001b[38;5;241m.\u001b[39madd(Conv1D(filters\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m, kernel_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m128\u001b[39m, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrelu\u001b[39m\u001b[38;5;124m'\u001b[39m, input_shape\u001b[38;5;241m=\u001b[39m(X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m],X_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m2\u001b[39m])))\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Add max pooling layer\u001b[39;00m\n\u001b[0;32m      8\u001b[0m model\u001b[38;5;241m.\u001b[39madd(MaxPooling1D(pool_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\trackable\\base.py:204\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 204\u001b[0m   result \u001b[38;5;241m=\u001b[39m method(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    206\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_self_setattr_tracking \u001b[38;5;241m=\u001b[39m previous_value  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mTensorShape(\n\u001b[0;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[0;32m    349\u001b[0m             \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilters]\n\u001b[0;32m    350\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m :])\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    355\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdue to downsampling in \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Consider \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincreasing the input size. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived input shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m which would produce \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput shape with a zero or negative value in a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdimension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv1d_2. Consider increasing the input size. Received input shape [None, 2, 1] which would produce output shape with a zero or negative value in a dimension."
     ]
    }
   ],
   "source": [
    "# Define your model\n",
    "model = Sequential()\n",
    "\n",
    "# Add 1D convolutional layer\n",
    "model.add(Conv1D(filters=16, kernel_size=128, activation='relu', input_shape=(X_train.shape[1],X_train.shape[2])))\n",
    "\n",
    "# Add max pooling layer\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Add additional convolutional layers or other layers as needed\n",
    "# model.add(Conv1D(filters=64, kernel_size=3, activation='relu'))\n",
    "# model.add(MaxPooling1D(pool_size=2))\n",
    "\n",
    "# Flatten the output of the last convolutional layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully connected layers\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dropout(0.2))  # Dropout for regularization\n",
    "\n",
    "# Output layer for binary classification\n",
    "model.add(Dense(2, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "065f6349-8f58-4cf5-b572-99dcf8079e33",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 91750, 2), found shape=(None, 2, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[66], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m      3\u001b[0m epochs,batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m150\u001b[39m, \u001b[38;5;241m64\u001b[39m\n\u001b[1;32m----> 4\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39mepochs, batch_size\u001b[38;5;241m=\u001b[39mbatch_size, validation_data\u001b[38;5;241m=\u001b[39m(X_val, y_val))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32m~\\AppData\\Local\\Temp\\__autograph_generated_filesk_l7cmq.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     14\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     retval_ \u001b[38;5;241m=\u001b[39m ag__\u001b[38;5;241m.\u001b[39mconverted_call(ag__\u001b[38;5;241m.\u001b[39mld(step_function), (ag__\u001b[38;5;241m.\u001b[39mld(\u001b[38;5;28mself\u001b[39m), ag__\u001b[38;5;241m.\u001b[39mld(iterator)), \u001b[38;5;28;01mNone\u001b[39;00m, fscope)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m     17\u001b[0m     do_return \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: in user code:\n\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1377, in train_function  *\n        return step_function(self, iterator)\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1360, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1349, in run_step  **\n        outputs = model.train_step(data)\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py\", line 1126, in train_step\n        y_pred = self(x, training=True)\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"C:\\Users\\1926\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential_1\" is incompatible with the layer: expected shape=(None, 91750, 2), found shape=(None, 2, 1)\n"
     ]
    }
   ],
   "source": [
    "plot_validation_loss = PlotValidationLoss(bin_factor)\n",
    "# Train the model\n",
    "epochs,batch_size=150, 64\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "#model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "500432a6-6f5f-41ea-bc20-0ceb3c47e461",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45875, 2)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf61d7-5f8d-4abd-92d7-729f6e73851f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_validation_loss = PlotValidationLoss(bin_factor)\n",
    "# Train the model\n",
    "epochs,batch_size=150, 64\n",
    "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, validation_data=(X_val, y_val))\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Optionally, save the model\n",
    "model.save('CNN_model_'+str(bin_factor)+'.h5')\n",
    "\n",
    "# Save the test accuracy in a text file\n",
    "with open('CNN_model_'+str(bin_factor)+'_test_accuracy_and_parameters.txt', 'w') as f:\n",
    "    f.write(f'Test Accuracy: {test_acc:.4f} \\n')\n",
    "    f.write('____________________________\\n')\n",
    "    f.write('Model Architecture:\\n\\n')\n",
    "    model.summary(print_fn=lambda x: f.write(x + '\\n'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
